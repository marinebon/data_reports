---
title: "SE US"
format: html
#echo: false
code-fold: true
warning: false
execute: 
  cache: true
---


```{R}
#| code-summary: get doi citations & print them
library(glue)
library(here)
library(httr)
library(jsonlite)
library(tidyr)

source(here("R/getCleanedData.R"))
df <- getCleanedData()

# Step 1: Split comma-separated DOIs into multiple rows
df <- df %>%
  separate_rows(doi, sep = ",") %>%
  filter(!is.na(doi) & doi != "")  # Remove empty or NA DOIs

# Initialize a list to store citing DOIs for each doi in the dataframe
all_citing <- list()

# Loop through each DOI in the dataframe
for (i in seq_along(df$doi)) {
  doi <- df$doi[i]
  
  # Skip if DOI is empty or NA
  if (is.na(doi) || doi == "") {
    message(glue("Skipping empty DOI at row {i}."))
    next
  }
  
  # Create the URL for the OpenCitations API
  opcit <- glue("https://opencitations.net/index/coci/api/v1/citations/{doi}")

    # Make the API request
  response <- tryCatch({
    GET(opcit)
  }, error = function(e) {
    message(glue("Error fetching data for DOI: {doi}, skipping."))
    NULL
  })
  
  # Check if response is valid
  if (is.null(response) || http_status(response)$category != "Success") {
    message(glue("Invalid response for DOI: {doi}, skipping."))
    next
  }
  
  # Parse JSON content
  result <- tryCatch({
    content(response, "parsed", type = "application/json")
  }, error = function(e) {
    message(glue("Error parsing JSON for DOI: {doi}, skipping."))
    NULL
  })
  
  # Extract citing DOIs if result is valid
  if (!is.null(result) && length(result) > 0) {
    citing <- lapply(result, function(x) x[['citing']])
    citing <- unlist(citing)
    
    # Store in the list
    all_citing[[doi]] <- citing
    
    # Print the citing DOIs
    print(glue("Citing DOIs for {doi}:"))
    print(citing)
  } else {
    message(glue("No citing DOIs found for {doi}."))
  }
}
```